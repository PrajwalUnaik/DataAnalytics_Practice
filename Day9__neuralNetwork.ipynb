{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp/q6kbvg7Y2ABaIrBsKfL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrajwalUnaik/DataAnalytics_Practice/blob/main/Day9__neuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feedforward Neural Network (FNN)** implemented with TensorFlow/Keras."
      ],
      "metadata": {
        "id": "4xA6SNsjezWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# 1. Load the Breast Cancer Wisconsin Dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to a DataFrame\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)  # Target: 0 = Malignant, 1 = Benign\n",
        "\n",
        "# 2. Data Preprocessing\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 3. Build the Neural Network Model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),  # Regularization\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification (output: 0 or 1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the Model\n",
        "history = model.fit(X_train, y_train, validation_split=0.1, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# 5. Evaluate the Model\n",
        "# Predictions on the test set\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()  # Convert probabilities to binary classes (0 or 1)\n",
        "\n",
        "# Calculate Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vfygQq6euFe",
        "outputId": "6f68de5e-43b3-43d8-b21d-f734e26ebbd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.3851 - loss: 0.7892 - val_accuracy: 0.8913 - val_loss: 0.5393\n",
            "Epoch 2/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8211 - loss: 0.5331 - val_accuracy: 0.9130 - val_loss: 0.3597\n",
            "Epoch 3/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8841 - loss: 0.3701 - val_accuracy: 0.9348 - val_loss: 0.2479\n",
            "Epoch 4/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9304 - loss: 0.2747 - val_accuracy: 0.9348 - val_loss: 0.1826\n",
            "Epoch 5/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9404 - loss: 0.2092 - val_accuracy: 0.9348 - val_loss: 0.1486\n",
            "Epoch 6/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9469 - loss: 0.1709 - val_accuracy: 0.9348 - val_loss: 0.1263\n",
            "Epoch 7/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.1332 - val_accuracy: 0.9348 - val_loss: 0.1122\n",
            "Epoch 8/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9650 - loss: 0.1202 - val_accuracy: 0.9348 - val_loss: 0.1029\n",
            "Epoch 9/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9669 - loss: 0.1249 - val_accuracy: 0.9565 - val_loss: 0.0969\n",
            "Epoch 10/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9769 - loss: 0.0799 - val_accuracy: 0.9565 - val_loss: 0.0931\n",
            "Epoch 11/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9776 - loss: 0.0874 - val_accuracy: 0.9783 - val_loss: 0.0892\n",
            "Epoch 12/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.0775 - val_accuracy: 0.9783 - val_loss: 0.0861\n",
            "Epoch 13/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9787 - loss: 0.0628 - val_accuracy: 0.9783 - val_loss: 0.0844\n",
            "Epoch 14/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9766 - loss: 0.0845 - val_accuracy: 0.9783 - val_loss: 0.0834\n",
            "Epoch 15/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9765 - loss: 0.0714 - val_accuracy: 0.9565 - val_loss: 0.0814\n",
            "Epoch 16/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9801 - loss: 0.0549 - val_accuracy: 0.9565 - val_loss: 0.0793\n",
            "Epoch 17/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0525 - val_accuracy: 0.9783 - val_loss: 0.0772\n",
            "Epoch 18/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0609 - val_accuracy: 0.9783 - val_loss: 0.0753\n",
            "Epoch 19/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0393 - val_accuracy: 0.9783 - val_loss: 0.0731\n",
            "Epoch 20/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0697 - val_accuracy: 0.9565 - val_loss: 0.0718\n",
            "Epoch 21/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0490 - val_accuracy: 0.9565 - val_loss: 0.0718\n",
            "Epoch 22/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0358 - val_accuracy: 0.9565 - val_loss: 0.0709\n",
            "Epoch 23/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0502 - val_accuracy: 0.9565 - val_loss: 0.0711\n",
            "Epoch 24/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0510 - val_accuracy: 0.9783 - val_loss: 0.0674\n",
            "Epoch 25/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0543 - val_accuracy: 0.9565 - val_loss: 0.0657\n",
            "Epoch 26/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9778 - loss: 0.0664 - val_accuracy: 0.9565 - val_loss: 0.0641\n",
            "Epoch 27/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0443 - val_accuracy: 0.9565 - val_loss: 0.0631\n",
            "Epoch 28/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9836 - loss: 0.0419 - val_accuracy: 0.9565 - val_loss: 0.0633\n",
            "Epoch 29/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0500 - val_accuracy: 0.9565 - val_loss: 0.0629\n",
            "Epoch 30/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0398 - val_accuracy: 0.9565 - val_loss: 0.0627\n",
            "Epoch 31/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9862 - loss: 0.0580 - val_accuracy: 0.9783 - val_loss: 0.0600\n",
            "Epoch 32/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0459 - val_accuracy: 0.9783 - val_loss: 0.0589\n",
            "Epoch 33/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0428 - val_accuracy: 0.9783 - val_loss: 0.0573\n",
            "Epoch 34/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 0.0211 - val_accuracy: 0.9783 - val_loss: 0.0566\n",
            "Epoch 35/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0512 - val_accuracy: 0.9783 - val_loss: 0.0548\n",
            "Epoch 36/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9890 - loss: 0.0376 - val_accuracy: 0.9783 - val_loss: 0.0531\n",
            "Epoch 37/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0290 - val_accuracy: 0.9783 - val_loss: 0.0535\n",
            "Epoch 38/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0311 - val_accuracy: 0.9783 - val_loss: 0.0535\n",
            "Epoch 39/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0161 - val_accuracy: 0.9783 - val_loss: 0.0525\n",
            "Epoch 40/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0353 - val_accuracy: 0.9783 - val_loss: 0.0507\n",
            "Epoch 41/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0180 - val_accuracy: 0.9783 - val_loss: 0.0487\n",
            "Epoch 42/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.0212 - val_accuracy: 0.9783 - val_loss: 0.0479\n",
            "Epoch 43/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0386 - val_accuracy: 0.9783 - val_loss: 0.0485\n",
            "Epoch 44/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0173 - val_accuracy: 1.0000 - val_loss: 0.0476\n",
            "Epoch 45/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0477\n",
            "Epoch 46/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0235 - val_accuracy: 1.0000 - val_loss: 0.0462\n",
            "Epoch 47/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.0234 - val_accuracy: 0.9783 - val_loss: 0.0490\n",
            "Epoch 48/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9864 - loss: 0.0351 - val_accuracy: 0.9783 - val_loss: 0.0500\n",
            "Epoch 49/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0266 - val_accuracy: 0.9783 - val_loss: 0.0489\n",
            "Epoch 50/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.0372 - val_accuracy: 0.9783 - val_loss: 0.0486\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Accuracy: 0.9561\n",
            "Precision: 0.9714\n",
            "Recall: 0.9577\n",
            "F1-Score: 0.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code uses a **Feedforward Neural Network (FNN)** implemented with TensorFlow/Keras. The architecture is specified using the `Sequential` API. Here's a breakdown of the model and its key features:\n",
        "\n",
        "### Model Architecture:\n",
        "1. **Input Layer**:  \n",
        "   - Input features are the standardized features from the Breast Cancer dataset (`X_train.shape[1]` = 30 features).  \n",
        "\n",
        "2. **Hidden Layers**:  \n",
        "   - **First Hidden Layer**:  \n",
        "     - 64 neurons with ReLU activation (`Dense(64, activation='relu')`).  \n",
        "     - **Dropout Layer**: Drops 30% of the neurons to prevent overfitting (`Dropout(0.3)`).  \n",
        "   - **Second Hidden Layer**:  \n",
        "     - 32 neurons with ReLU activation.  \n",
        "     - **Dropout Layer**: Another 30% dropout rate.\n",
        "\n",
        "3. **Output Layer**:  \n",
        "   - A single neuron with a sigmoid activation function (`Dense(1, activation='sigmoid')`).  \n",
        "   - This outputs a probability score (between 0 and 1), indicating the likelihood of the input belonging to the positive class (Benign in this case).\n",
        "\n",
        "### Model Purpose:\n",
        "This model performs **binary classification** using **logistic regression in the output layer** (`sigmoid` activation). The loss function used (`binary_crossentropy`) is suitable for binary classification problems.\n",
        "\n",
        "### Optimization:\n",
        "The model is optimized using the **Adam optimizer**, a variant of gradient descent that adapts learning rates for better convergence.\n",
        "\n",
        "### Metrics:\n",
        "The key performance metrics are:\n",
        "- **Accuracy**: Overall correctness of predictions.\n",
        "- **Precision**: Fraction of predicted positives that are true positives.\n",
        "- **Recall**: Fraction of true positives correctly identified.\n",
        "- **F1-Score**: Harmonic mean of precision and recall (balances both).\n",
        "\n",
        "This architecture is a basic example of a deep neural network, specifically tailored for tabular data with a binary classification target.\n"
      ],
      "metadata": {
        "id": "STPUYTepgrYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Convolutional Neural Network (CNN)** implemented with TensorFlow/Keras."
      ],
      "metadata": {
        "id": "UEZy_oxhf6Wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load the Breast Cancer Wisconsin Dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to a DataFrame\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)  # Target: 0 = Malignant, 1 = Benign\n",
        "\n",
        "# 2. Data Preprocessing\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN\n",
        "# Assuming each \"image\" is a 6x5 grid (30 features reshaped into 6 rows and 5 columns)\n",
        "X_train = X_train.reshape(X_train.shape[0], 6, 5, 1)  # Add a channel dimension\n",
        "X_test = X_test.reshape(X_test.shape[0], 6, 5, 1)\n",
        "\n",
        "# 3. Build the CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(6, 5, 1)),  # Convolutional layer\n",
        "    MaxPooling2D((2, 2)),  # Pooling layer\n",
        "    Flatten(),  # Flatten 2D feature maps into a 1D vector\n",
        "    Dense(64, activation='relu'),  # Fully connected layer\n",
        "    Dropout(0.3),  # Regularization\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the Model\n",
        "history = model.fit(X_train, y_train, validation_split=0.1, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# 5. Evaluate the Model\n",
        "# Predictions on the test set\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()  # Convert probabilities to binary classes (0 or 1)\n",
        "\n",
        "# Calculate Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-5rRXuEgB1o",
        "outputId": "3255357c-725b-4758-f8e9-1b914f42eda8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7347 - loss: 0.6301 - val_accuracy: 0.9348 - val_loss: 0.4479\n",
            "Epoch 2/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9027 - loss: 0.4515 - val_accuracy: 0.9348 - val_loss: 0.3085\n",
            "Epoch 3/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9016 - loss: 0.3464 - val_accuracy: 0.9565 - val_loss: 0.2207\n",
            "Epoch 4/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9137 - loss: 0.2773 - val_accuracy: 0.9348 - val_loss: 0.1744\n",
            "Epoch 5/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2232 - val_accuracy: 0.9348 - val_loss: 0.1523\n",
            "Epoch 6/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9294 - loss: 0.2087 - val_accuracy: 0.9565 - val_loss: 0.1371\n",
            "Epoch 7/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9500 - loss: 0.1680 - val_accuracy: 0.9565 - val_loss: 0.1252\n",
            "Epoch 8/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9537 - loss: 0.1446 - val_accuracy: 0.9565 - val_loss: 0.1184\n",
            "Epoch 9/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9542 - loss: 0.1394 - val_accuracy: 0.9565 - val_loss: 0.1121\n",
            "Epoch 10/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.1377 - val_accuracy: 0.9783 - val_loss: 0.1090\n",
            "Epoch 11/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9726 - loss: 0.1115 - val_accuracy: 0.9565 - val_loss: 0.1047\n",
            "Epoch 12/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9659 - loss: 0.1090 - val_accuracy: 0.9565 - val_loss: 0.1018\n",
            "Epoch 13/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9722 - loss: 0.1147 - val_accuracy: 0.9565 - val_loss: 0.1023\n",
            "Epoch 14/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.1149 - val_accuracy: 0.9565 - val_loss: 0.0996\n",
            "Epoch 15/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9713 - loss: 0.0922 - val_accuracy: 0.9565 - val_loss: 0.1010\n",
            "Epoch 16/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.1141 - val_accuracy: 0.9565 - val_loss: 0.0987\n",
            "Epoch 17/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9816 - loss: 0.0945 - val_accuracy: 0.9565 - val_loss: 0.0984\n",
            "Epoch 18/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0817 - val_accuracy: 0.9565 - val_loss: 0.1025\n",
            "Epoch 19/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9559 - loss: 0.1235 - val_accuracy: 0.9565 - val_loss: 0.1021\n",
            "Epoch 20/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9661 - loss: 0.0961 - val_accuracy: 0.9565 - val_loss: 0.0971\n",
            "Epoch 21/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9714 - loss: 0.0859 - val_accuracy: 0.9565 - val_loss: 0.0996\n",
            "Epoch 22/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.1265 - val_accuracy: 0.9565 - val_loss: 0.1014\n",
            "Epoch 23/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9774 - loss: 0.0989 - val_accuracy: 0.9565 - val_loss: 0.0997\n",
            "Epoch 24/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9606 - loss: 0.1030 - val_accuracy: 0.9565 - val_loss: 0.0994\n",
            "Epoch 25/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9697 - loss: 0.1079 - val_accuracy: 0.9565 - val_loss: 0.1021\n",
            "Epoch 26/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9807 - loss: 0.0927 - val_accuracy: 0.9565 - val_loss: 0.0996\n",
            "Epoch 27/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9745 - loss: 0.0735 - val_accuracy: 0.9565 - val_loss: 0.1036\n",
            "Epoch 28/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0662 - val_accuracy: 0.9565 - val_loss: 0.1009\n",
            "Epoch 29/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9703 - loss: 0.0797 - val_accuracy: 0.9565 - val_loss: 0.0986\n",
            "Epoch 30/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9776 - loss: 0.0535 - val_accuracy: 0.9565 - val_loss: 0.0986\n",
            "Epoch 31/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9679 - loss: 0.1062 - val_accuracy: 0.9565 - val_loss: 0.1018\n",
            "Epoch 32/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0561 - val_accuracy: 0.9565 - val_loss: 0.1052\n",
            "Epoch 33/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9689 - loss: 0.0923 - val_accuracy: 0.9565 - val_loss: 0.1027\n",
            "Epoch 34/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 0.0518 - val_accuracy: 0.9565 - val_loss: 0.1038\n",
            "Epoch 35/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0604 - val_accuracy: 0.9565 - val_loss: 0.1007\n",
            "Epoch 36/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9728 - loss: 0.0614 - val_accuracy: 0.9565 - val_loss: 0.0979\n",
            "Epoch 37/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9798 - loss: 0.0653 - val_accuracy: 0.9565 - val_loss: 0.1028\n",
            "Epoch 38/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.0763 - val_accuracy: 0.9565 - val_loss: 0.1042\n",
            "Epoch 39/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9879 - loss: 0.0503 - val_accuracy: 0.9565 - val_loss: 0.1042\n",
            "Epoch 40/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9846 - loss: 0.0515 - val_accuracy: 0.9565 - val_loss: 0.0996\n",
            "Epoch 41/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0463 - val_accuracy: 0.9565 - val_loss: 0.1003\n",
            "Epoch 42/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0590 - val_accuracy: 0.9565 - val_loss: 0.1024\n",
            "Epoch 43/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9812 - loss: 0.0638 - val_accuracy: 0.9565 - val_loss: 0.1002\n",
            "Epoch 44/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0393 - val_accuracy: 0.9565 - val_loss: 0.1042\n",
            "Epoch 45/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0394 - val_accuracy: 0.9565 - val_loss: 0.1057\n",
            "Epoch 46/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 0.0512 - val_accuracy: 0.9565 - val_loss: 0.1018\n",
            "Epoch 47/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0429 - val_accuracy: 0.9565 - val_loss: 0.1008\n",
            "Epoch 48/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.0632 - val_accuracy: 0.9565 - val_loss: 0.1033\n",
            "Epoch 49/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.0867 - val_accuracy: 0.9565 - val_loss: 0.1046\n",
            "Epoch 50/50\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0606 - val_accuracy: 0.9565 - val_loss: 0.1049\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Accuracy: 0.9561\n",
            "Precision: 0.9583\n",
            "Recall: 0.9718\n",
            "F1-Score: 0.9650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Key Points\n",
        "\n",
        "1. **Reshaping**  \n",
        "   - The features (30 in total) are reshaped into a `(6, 5, 1)` grid for CNN processing.\n",
        "\n",
        "2. **Convolution and Pooling**  \n",
        "   - The `Conv2D` layer extracts **spatial patterns**.  \n",
        "   - The `MaxPooling2D` layer reduces the **spatial dimensions** and helps prevent **overfitting**.\n",
        "\n",
        "3. **Flattening**  \n",
        "   - Converts the **2D feature maps** into a **1D vector** for input to fully connected layers.\n",
        "\n",
        "4. **Output**  \n",
        "   - A **sigmoid activation function** predicts the probability of the **positive class**.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "UShGj1zyg-76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# 1. Load the Breast Cancer Wisconsin Dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to a DataFrame\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)  # Target: 0 = Malignant, 1 = Benign\n",
        "\n",
        "# 2. Data Preprocessing\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN\n",
        "# Treat each feature as a time step (sequence length = 30, features per step = 1)\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# 3. Build the RNN Model\n",
        "model = Sequential([\n",
        "    LSTM(64, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])),  # LSTM layer\n",
        "    Dropout(0.3),  # Regularization\n",
        "    Dense(32, activation='relu'),  # Fully connected layer\n",
        "    Dropout(0.3),  # Regularization\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. Train the Model\n",
        "history = model.fit(X_train, y_train, validation_split=0.1, epochs=50, batch_size=32, verbose=1)\n",
        "\n",
        "# 5. Evaluate the Model\n",
        "# Predictions on the test set\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()  # Convert probabilities to binary classes (0 or 1)\n",
        "\n",
        "# Calculate Metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "hPxauMq_g5QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Key Details\n",
        "\n",
        "1. **Reshaping**  \n",
        "   - The input is reshaped to have a sequence length of 30 (one time step per feature) and one feature per step (`(n_samples, 30, 1)`).\n",
        "\n",
        "2. **RNN Layer**  \n",
        "   - The `LSTM` layer processes the sequential data and captures patterns across the sequence of features.  \n",
        "   - Other RNN layers like `GRU` or vanilla `SimpleRNN` can also be used, but `LSTM` generally performs better for tasks requiring memory.\n",
        "\n",
        "3. **Dropout Regularization**  \n",
        "   - Dropout layers are used after the LSTM and dense layers to prevent overfitting.\n",
        "\n",
        "4. **Output**  \n",
        "   - A **sigmoid activation function** predicts the probability of the **positive class**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VNNsIKsxhP40"
      }
    }
  ]
}